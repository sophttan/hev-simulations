
R version 4.2.2 Patched (2022-11-10 r83330) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list = ls())
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 275504 14.8     663411 35.5   469120 25.1
Vcells 463347  3.6    8388608 64.0  1822672 14.0
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(foreach)
> library(doParallel)
Loading required package: iterators
Loading required package: parallel
> 
> # Set up the number of cores used for parallelization.
> num_cores <- 24
> registerDoParallel(num_cores)
> 
> #########################
> #### SEIR Simulation ####
> #########################
> time <- 365 # Number of days.
> inc <- 28 # Average incubation period length.
> inf <- 7 # Average infectious period length.
> N <- 1000 # Population size.
> 
> create_hh <- function() {
+   # Randomly sample household sizes such that total population is 1000 
+   # individuals.
+   hh_size <- sample(x = c(3, 4, 5, 6), size = 340, replace = T)
+   
+   # Keep households such that total population is < 1000.
+   hh_size <- hh_size[which(cumsum(hh_size) < N)]
+   
+   leftover <- N - sum(hh_size)
+   if (leftover < 3) {
+     hh <- 1:length(hh_size)
+     sampled <- sample(hh[hh_size < 6], leftover)
+     hh_size[sampled] <- hh_size[sampled] + 1
+   } else {
+     hh_size <- c(hh_size, leftover)
+   }
+   return(hh_size)
+ }
> 
> SEIR <- function(params, inc, inf, verbose = F) {
+   hh_size <- create_hh()
+   
+   # Create frame for running the simulation.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # S: susceptibility status.
+   # E: exposed status.
+   # E_count: number of days since exposed.
+   # I: infectious status.
+   # I_count: number of days since infectious.
+   # R: recovered status.
+   # INC: incubation period.
+   # INF: infectious period.
+   data <- data.frame(ID = 1:N,
+                     SIZE = rep(hh_size, times = hh_size),
+                     HH = rep(1:length(hh_size), times = hh_size), 
+                     S = c(0, rep(1, N - 1)), 
+                     E = c(1, rep(0, N - 1)),
+                     E_count = c(1, rep(0, N - 1)), 
+                     I = 0,
+                     I_count = 0, 
+                     R = 0, 
+                     INC = c(round(rnorm(1, inc, 2)), rep(0, N - 1)),
+                     INF = 0)
+   
+   # Create frame for storing results.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # TYPE: the kind of infection: household (H), community (C), or both (B).
+   # TIME: when the individual became infectious.
+   # S_num: number of susceptible people in individual's household when their 
+   #        infectious period begins.
+   # I_num: number of people in household that this individual infected over 
+   #        their infectious period.
+   results <- data[, 1:3] %>% mutate(TYPE = NA, TIME = NA, S_num = NA, I_num = 0)
+   results$TYPE[1] <- '0'
+   
+   for(t in 1:time) {
+     if (verbose) {
+       if (t %% 10 == 0) {
+         cat(paste0(t, ' '))
+       }
+     }
+     
+     # Anyone who has been infectious for as many days as their infectious period
+     # is now recovered.
+     recovered <- (data$INF > 0) & (data$I_count == data$INF)
+     if(sum(recovered, na.rm = T) > 0) {
+       data$R[recovered] <- 1
+       data$I[recovered] <- 0
+       data$I_count[recovered] <- 0 
+     }
+     
+     # Anyone who has been incubating for as many days as their incubation period
+     # is now infectious.
+     new_inf <- (data$INC > 0) & (data$E_count == data$INC)
+     num_new_inf <- sum(new_inf, na.rm = T)
+     if(num_new_inf > 0) {
+       # Change status to newly infectious and add infectious period.
+       data$I[new_inf] <- 1
+       random_inf <- rnorm(num_new_inf, mean = inf, sd = 1) %>% round()
+       data$INF[new_inf] <- random_inf
+       
+       # Remove exposure status and exposure count.
+       data$E[new_inf] <- 0
+       data$E_count[new_inf] <- 0 
+       
+       # Record time at which infectious period starts.
+       results$TIME[new_inf] <- t
+       
+       # Save the number of susceptible people in each infectious individual's 
+       # household.
+       S_data <- data %>% group_by(HH) %>% 
+         mutate(S_tot = sum(S)) %>% 
+         select(HH, S_tot)
+       results$S_num[new_inf == 1] <- S_data$S_tot[new_inf == 1]
+     }
+     
+     # I_H is the number of infections inside each household.
+     # I_C is the number of infections outside each household.
+     I_data <- data %>% group_by(HH) %>% 
+       mutate(I_H = sum(I)) %>% 
+       ungroup() %>% 
+       mutate(I_C = sum(I) - I_H)
+     
+     # Calculate household risk and community risk.
+     beta_H <- params[1]
+     beta_C <- params[2]
+     risk_H <- beta_H * data$S * I_data$I_H / N
+     risk_C <- beta_C * data$S * I_data$I_C / N
+     
+     # Each individual is infected from their household or community 
+     # independently with probabilities risk_H and risk_C.
+     new_inf_H <- rbinom(nrow(data), 1, risk_H)
+     new_inf_C <- rbinom(nrow(data), 1, risk_C)
+     
+     new_exposed <- (new_inf_H == 1) | (new_inf_C == 1)
+     num_new_exposed <- sum(new_exposed, na.rm = T)
+     if (num_new_exposed > 0) {
+       # Change status to newly exposed and add incubation period.
+       data$E[new_exposed] <- 1
+       random_inc <- rnorm(num_new_exposed, mean = inc, sd = 2) %>% round()
+       data$INC[new_exposed] <- random_inc
+       
+       # Remove susceptible status.
+       data$S[new_exposed] <- 0
+       
+       # Label community infections with C and household infections with H.
+       results$TYPE[new_inf_C == 1] <- 'C'
+       results$TYPE[new_inf_H == 1] <- 'H'
+       
+       # Get number of new infections in each household.
+       I_data <- I_data %>%
+         select(ID, HH, I, I_H) %>%
+         mutate(new_I_H = new_inf_H) %>%
+         group_by(HH) %>%
+         # Find households with at least 1 currently infectious individual. If 
+         # exactly 1 infectious individual in household, assign all new H 
+         # exposures to that individual. If there are multiple infectious 
+         # individuals, assign all infections to the infectious individual with 
+         # the first ID.
+         mutate(new_I_H = ifelse(I == 1 & ID == first(ID[I == 1]), 
+                                 sum(new_I_H), 0))
+       
+       results$I_num <- results$I_num + I_data$new_I_H
+         
+       # Label individuals with both a household and community infection with B.
+       results$TYPE[(new_inf_H == 1) & (new_inf_C == 1)] <- 'B'
+     }
+     
+     # Increment exposure and infectious counters.
+     data$E_count[data$E == 1] <- data$E_count[data$E == 1] + 1
+     data$I_count[data$I == 1] <- data$I_count[data$I == 1] + 1
+   }
+   return(results)
+ }
> 
> metrics <- function(results) {
+   # Incidence is the proportion of the population that became infected.
+   idc <- mean(!is.na(results$TIME))
+   
+   # If incidence is 0, the SAR is undefined.
+   sar <- NA
+   if (idc != 0) {
+     # The SAR is the average SAR for each individual that was infectious.
+     sar <- mean(results$I_num / results$S_num, na.rm = T)
+   }
+   return(c(idc, sar))
+ }
> 
> ##############################
> #### Metropolis Algorithm ####
> ##############################
> score <- function(obs, target) {
+   # The score is the L² distance of the observed values from the target.
+   return(sum((obs - target)^2))
+ }
> 
> # The likelihood is calculated by first averaging the incidence and SAR over n
> # simulations with the state parameters. The likelihood is the negative log
> # score of the average incidence and SAR.
> likelihood <- function(state, target, n = 300) {
+   # If either parameter is nonpositive, do not transition to that state.
+   if (any(state <= 0)) {
+     return(-Inf)
+   }
+   # Otherwise, find the average incidence and SAR and compute likelihood.
+   vals <- foreach (i = 1:n, .combine = c) %dopar% {
+     results <- SEIR(state, inc, inf)
+     metrics(results)
+   }
+   vals <- matrix(vals, n, byrow = T)
+   avg_vals <- colMeans(vals)
+   return(-log(score(avg_vals, target)))
+ }
> 
> # Proposal function
> q <- function(state, sds = c(0.1, 0.001)) {
+   # Sample from a multivariate normal distributions centered at the current 
+   # state. The SDs roughly correspond to the step-size of the chain for each 
+   # parameter.
+   return(rnorm(n = 2, mean = state, sd = sds))
+ }
> 
> # MCMC
> metropolis <- function(start, target, num_sim, num_iter) {
+   path <- matrix(NA, num_iter + 1, 2)
+   liks <- rep(NA, num_iter + 1)
+   
+   # Initialize current state.
+   curr <- start
+   curr_lik <- likelihood(curr, target, num_sim)
+   
+   # Initialize best state.
+   best <- curr
+   best_lik <- curr_lik
+   for (i in 1:num_iter) {
+     # Save the current state and its likelihood.
+     path[i, ] <- curr
+     liks[i] <- curr_lik
+     
+     # Get a proposed state and calculate its likelihood.
+     prop <- q(curr)
+     prop_lik <- likelihood(prop, target, num_sim)
+     
+     # Compute the ratio of the scores of the two states and generate a uniform 
+     # bit.
+     r <- exp(prop_lik - curr_lik)
+     p <- runif(1)
+     
+     # Print the current progress.
+     message(paste0(i, '\t[', round(curr[1], 3), '\t', round(curr[2], 5), 
+                    ']\t', round(curr_lik, 3), '\t', 
+                    '\t[', round(prop[1], 3), '\t', round(prop[2], 5), ']\t',
+                    round(prop_lik, 3), '\t', round(r, 3), '\t', round(p, 3)))
+     
+     # Transition if the proposed state is better or if the coin flip succeeds.
+     if (p < r) { 
+       curr <- prop
+       curr_lik <- prop_lik
+       
+       # If the new likelihood is better than the best we've seen so far, replace 
+       # the best.
+       if (curr_lik > best_lik) {
+         best <- curr
+         best_lik <- curr_lik
+       }
+     }
+     
+     # Save the path, best state, and likelihoods so far.
+     write.table(path, file = '30/path.txt', row.names = F, col.names = F)
+     write.table(liks, file = '30/liks.txt', row.names = F, col.names = F)
+     write.table(best, file = '30/best.txt', row.names = F, col.names = F)
+   }
+   path[num_iter + 1, ] <- curr
+   liks[num_iter + 1] <- curr_lik
+   return(list(path, liks, best))
+ }
> 
> # Solve for optimal values via MCMC.
> target <- c(0.30, 0.25)
> start <- c(51.2386100875685, 0.122167209713071)
> results <- metropolis(start, target, num_sim = 1000, num_iter = 500)
1	[51.239	0.12217]	8.986		[51.297	0.12279]	12.451	31.973	0.615
2	[51.297	0.12279]	12.451		[51.205	0.12152]	6.811	0.004	0.959
3	[51.297	0.12279]	12.451		[51.358	0.121]	9.246	0.041	0.279
4	[51.297	0.12279]	12.451		[51.391	0.12106]	7.356	0.006	0.126
5	[51.297	0.12279]	12.451		[51.363	0.12159]	7.817	0.01	0.526
6	[51.297	0.12279]	12.451		[51.305	0.12436]	8.778	0.025	0.383
7	[51.297	0.12279]	12.451		[51.156	0.12286]	9.815	0.072	0.776
8	[51.297	0.12279]	12.451		[51.399	0.12413]	9.325	0.044	0.665
9	[51.297	0.12279]	12.451		[51.264	0.12209]	6.832	0.004	0.635
10	[51.297	0.12279]	12.451		[51.463	0.12174]	7.197	0.005	0.533
11	[51.297	0.12279]	12.451		[51.216	0.1206]	7.548	0.007	0.264
12	[51.297	0.12279]	12.451		[51.253	0.12205]	8.567	0.021	0.492
13	[51.297	0.12279]	12.451		[51.058	0.12033]	6.851	0.004	0.912
14	[51.297	0.12279]	12.451		[51.462	0.12172]	8.012	0.012	0.5
15	[51.297	0.12279]	12.451		[51.162	0.12226]	7.499	0.007	0.198
16	[51.297	0.12279]	12.451		[51.347	0.12446]	8.908	0.029	0.438
17	[51.297	0.12279]	12.451		[51.194	0.12051]	7.62	0.008	0.629
18	[51.297	0.12279]	12.451		[51.381	0.12386]	8.919	0.029	0.96
19	[51.297	0.12279]	12.451		[51.419	0.12124]	8.326	0.016	0.12
20	[51.297	0.12279]	12.451		[51.329	0.12194]	8.324	0.016	0.299
21	[51.297	0.12279]	12.451		[51.413	0.12358]	11.249	0.301	0.639
22	[51.297	0.12279]	12.451		[51.235	0.12243]	9.196	0.039	0.223
23	[51.297	0.12279]	12.451		[51.335	0.12259]	9.906	0.079	0.751
24	[51.297	0.12279]	12.451		[51.298	0.12257]	8.61	0.021	0.661
25	[51.297	0.12279]	12.451		[51.379	0.12283]	9.189	0.038	0.352
26	[51.297	0.12279]	12.451		[51.326	0.12193]	8.48	0.019	0.411
27	[51.297	0.12279]	12.451		[51.414	0.12343]	8.234	0.015	0.322
28	[51.297	0.12279]	12.451		[51.462	0.12198]	7.419	0.007	0.86
29	[51.297	0.12279]	12.451		[51.361	0.12395]	8.6	0.021	0.364
30	[51.297	0.12279]	12.451		[51.404	0.12317]	9.164	0.037	0.126
31	[51.297	0.12279]	12.451		[51.292	0.12255]	8.124	0.013	0.69
32	[51.297	0.12279]	12.451		[51.349	0.12168]	7.533	0.007	0.133
33	[51.297	0.12279]	12.451		[51.329	0.12196]	11.104	0.26	0.708
34	[51.297	0.12279]	12.451		[51.128	0.12344]	6.9	0.004	0.2
35	[51.297	0.12279]	12.451		[51.335	0.12414]	9.05	0.033	0.778
36	[51.297	0.12279]	12.451		[51.243	0.12298]	7.398	0.006	0.426
37	[51.297	0.12279]	12.451		[51.141	0.12207]	7.214	0.005	0.568
38	[51.297	0.12279]	12.451		[51.349	0.1235]	7.966	0.011	0.845
39	[51.297	0.12279]	12.451		[51.364	0.12271]	7.728	0.009	0.834
40	[51.297	0.12279]	12.451		[51.29	0.12069]	7.523	0.007	0.136
41	[51.297	0.12279]	12.451		[51.436	0.12313]	10.232	0.109	0.488
42	[51.297	0.12279]	12.451		[51.382	0.1233]	9.22	0.04	0.102
43	[51.297	0.12279]	12.451		[51.114	0.12156]	7.031	0.004	0.842
44	[51.297	0.12279]	12.451		[51.383	0.12178]	9.64	0.06	0.822
45	[51.297	0.12279]	12.451		[51.347	0.12331]	9.452	0.05	0.292
46	[51.297	0.12279]	12.451		[51.182	0.12282]	9.355	0.045	0.331
47	[51.297	0.12279]	12.451		[51.268	0.12225]	7.752	0.009	0.454
48	[51.297	0.12279]	12.451		[51.243	0.12257]	9.312	0.043	0.563
49	[51.297	0.12279]	12.451		[51.244	0.12311]	7.19	0.005	0.553
50	[51.297	0.12279]	12.451		[51.331	0.12188]	7.418	0.007	0.379
51	[51.297	0.12279]	12.451		[51.313	0.12302]	8.849	0.027	0.834
52	[51.297	0.12279]	12.451		[51.163	0.12266]	10.456	0.136	0.898
