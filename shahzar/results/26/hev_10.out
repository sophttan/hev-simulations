
R version 4.2.2 Patched (2022-11-10 r83330) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list = ls())
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 275504 14.8     663411 35.5   469120 25.1
Vcells 463347  3.6    8388608 64.0  1822672 14.0
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(foreach)
> library(doParallel)
Loading required package: iterators
Loading required package: parallel
> 
> # Set up the number of cores used for parallelization.
> num_cores <- 24
> registerDoParallel(num_cores)
> 
> #########################
> #### SEIR Simulation ####
> #########################
> time <- 365 # Number of days.
> inc <- 28 # Average incubation period length.
> inf <- 7 # Average infectious period length.
> N <- 1000 # Population size.
> 
> create_hh <- function() {
+   # Randomly sample household sizes such that total population is 1000 
+   # individuals.
+   hh_size <- sample(x = c(3, 4, 5, 6), size = 340, replace = T)
+   
+   # Keep households such that total population is < 1000.
+   hh_size <- hh_size[which(cumsum(hh_size) < N)]
+   
+   leftover <- N - sum(hh_size)
+   if (leftover < 3) {
+     hh <- 1:length(hh_size)
+     sampled <- sample(hh[hh_size < 6], leftover)
+     hh_size[sampled] <- hh_size[sampled] + 1
+   } else {
+     hh_size <- c(hh_size, leftover)
+   }
+   return(hh_size)
+ }
> 
> SEIR <- function(params, inc, inf, verbose = F) {
+   hh_size <- create_hh()
+   
+   # Create frame for running the simulation.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # S: susceptibility status.
+   # E: exposed status.
+   # E_count: number of days since exposed.
+   # I: infectious status.
+   # I_count: number of days since infectious.
+   # R: recovered status.
+   # INC: incubation period.
+   # INF: infectious period.
+   data <- data.frame(ID = 1:N,
+                     SIZE = rep(hh_size, times = hh_size),
+                     HH = rep(1:length(hh_size), times = hh_size), 
+                     S = c(0, rep(1, N - 1)), 
+                     E = c(1, rep(0, N - 1)),
+                     E_count = c(1, rep(0, N - 1)), 
+                     I = 0,
+                     I_count = 0, 
+                     R = 0, 
+                     INC = c(round(rnorm(1, inc, 2)), rep(0, N - 1)),
+                     INF = 0)
+   
+   # Create frame for storing results.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # TYPE: the kind of infection: household (H), community (C), or both (B).
+   # TIME: when the individual became infectious.
+   # S_num: number of susceptible people in individual's household when their 
+   #        infectious period begins.
+   # I_num: number of people in household that this individual infected over 
+   #        their infectious period.
+   results <- data[, 1:3] %>% mutate(TYPE = NA, TIME = NA, S_num = NA, I_num = 0)
+   results$TYPE[1] <- '0'
+   
+   for(t in 1:time) {
+     if (verbose) {
+       if (t %% 10 == 0) {
+         cat(paste0(t, ' '))
+       }
+     }
+     
+     # Anyone who has been infectious for as many days as their infectious period
+     # is now recovered.
+     recovered <- (data$INF > 0) & (data$I_count == data$INF)
+     if(sum(recovered, na.rm = T) > 0) {
+       data$R[recovered] <- 1
+       data$I[recovered] <- 0
+       data$I_count[recovered] <- 0 
+     }
+     
+     # Anyone who has been incubating for as many days as their incubation period
+     # is now infectious.
+     new_inf <- (data$INC > 0) & (data$E_count == data$INC)
+     num_new_inf <- sum(new_inf, na.rm = T)
+     if(num_new_inf > 0) {
+       # Change status to newly infectious and add infectious period.
+       data$I[new_inf] <- 1
+       random_inf <- rnorm(num_new_inf, mean = inf, sd = 1) %>% round()
+       data$INF[new_inf] <- random_inf
+       
+       # Remove exposure status and exposure count.
+       data$E[new_inf] <- 0
+       data$E_count[new_inf] <- 0 
+       
+       # Record time at which infectious period starts.
+       results$TIME[new_inf] <- t
+       
+       # Save the number of susceptible people in each infectious individual's 
+       # household.
+       S_data <- data %>% group_by(HH) %>% 
+         mutate(S_tot = sum(S)) %>% 
+         select(HH, S_tot)
+       results$S_num[new_inf == 1] <- S_data$S_tot[new_inf == 1]
+     }
+     
+     # I_H is the number of infections inside each household.
+     # I_C is the number of infections outside each household.
+     I_data <- data %>% group_by(HH) %>% 
+       mutate(I_H = sum(I)) %>% 
+       ungroup() %>% 
+       mutate(I_C = sum(I) - I_H)
+     
+     # Calculate household risk and community risk.
+     beta_H <- params[1]
+     beta_C <- params[2]
+     risk_H <- beta_H * data$S * I_data$I_H / N
+     risk_C <- beta_C * data$S * I_data$I_C / N
+     
+     # Each individual is infected from their household or community 
+     # independently with probabilities risk_H and risk_C.
+     new_inf_H <- rbinom(nrow(data), 1, risk_H)
+     new_inf_C <- rbinom(nrow(data), 1, risk_C)
+     
+     new_exposed <- (new_inf_H == 1) | (new_inf_C == 1)
+     num_new_exposed <- sum(new_exposed, na.rm = T)
+     if (num_new_exposed > 0) {
+       # Change status to newly exposed and add incubation period.
+       data$E[new_exposed] <- 1
+       random_inc <- rnorm(num_new_exposed, mean = inc, sd = 2) %>% round()
+       data$INC[new_exposed] <- random_inc
+       
+       # Remove susceptible status.
+       data$S[new_exposed] <- 0
+       
+       # Label community infections with C and household infections with H.
+       results$TYPE[new_inf_C == 1] <- 'C'
+       results$TYPE[new_inf_H == 1] <- 'H'
+       
+       # Get number of new infections in each household.
+       I_data <- I_data %>%
+         select(ID, HH, I, I_H) %>%
+         mutate(new_I_H = new_inf_H) %>%
+         group_by(HH) %>%
+         # Find households with at least 1 currently infectious individual. If 
+         # exactly 1 infectious individual in household, assign all new H 
+         # exposures to that individual. If there are multiple infectious 
+         # individuals, assign all infections to the infectious individual with 
+         # the first ID.
+         mutate(new_I_H = ifelse(I == 1 & ID == first(ID[I == 1]), 
+                                 sum(new_I_H), 0))
+       
+       results$I_num <- results$I_num + I_data$new_I_H
+         
+       # Label individuals with both a household and community infection with B.
+       results$TYPE[(new_inf_H == 1) & (new_inf_C == 1)] <- 'B'
+     }
+     
+     # Increment exposure and infectious counters.
+     data$E_count[data$E == 1] <- data$E_count[data$E == 1] + 1
+     data$I_count[data$I == 1] <- data$I_count[data$I == 1] + 1
+   }
+   return(results)
+ }
> 
> metrics <- function(results) {
+   # Incidence is the proportion of the population that became infected.
+   idc <- mean(!is.na(results$TIME))
+   
+   # If incidence is 0, the SAR is undefined.
+   sar <- NA
+   if (idc != 0) {
+     # The SAR is the average SAR for each individual that was infectious.
+     sar <- mean(results$I_num / results$S_num, na.rm = T)
+   }
+   return(c(idc, sar))
+ }
> 
> ##############################
> #### Metropolis Algorithm ####
> ##############################
> score <- function(obs, target) {
+   # The score is the L² distance of the observed values from the target.
+   return(sum((obs - target)^2))
+ }
> 
> # The likelihood is calculated by first averaging the incidence and SAR over n
> # simulations with the state parameters. The likelihood is the negative log
> # score of the average incidence and SAR.
> likelihood <- function(state, target, n = 300) {
+   # If either parameter is nonpositive, do not transition to that state.
+   if (any(state <= 0)) {
+     return(-Inf)
+   }
+   # Otherwise, find the average incidence and SAR and compute likelihood.
+   vals <- foreach (i = 1:n, .combine = c) %dopar% {
+     results <- SEIR(state, inc, inf)
+     metrics(results)
+   }
+   vals <- matrix(vals, n, byrow = T)
+   avg_vals <- colMeans(vals)
+   return(-log(score(avg_vals, target)))
+ }
> 
> # Proposal function
> q <- function(state, sds = c(0.1, 0.001)) {
+   # Sample from a multivariate normal distributions centered at the current 
+   # state. The SDs roughly correspond to the step-size of the chain for each 
+   # parameter.
+   return(rnorm(n = 2, mean = state, sd = sds))
+ }
> 
> # MCMC
> metropolis <- function(start, target, num_sim, num_iter) {
+   path <- matrix(NA, num_iter + 1, 2)
+   liks <- rep(NA, num_iter + 1)
+   
+   # Initialize current state.
+   curr <- start
+   curr_lik <- likelihood(curr, target, num_sim)
+   
+   # Initialize best state.
+   best <- curr
+   best_lik <- curr_lik
+   for (i in 1:num_iter) {
+     # Save the current state and its likelihood.
+     path[i, ] <- curr
+     liks[i] <- curr_lik
+     
+     # Get a proposed state and calculate its likelihood.
+     prop <- q(curr)
+     prop_lik <- likelihood(prop, target, num_sim)
+     
+     # Compute the ratio of the scores of the two states and generate a uniform 
+     # bit.
+     r <- exp(prop_lik - curr_lik)
+     p <- runif(1)
+     
+     # Print the current progress.
+     message(paste0(i, '\t[', round(curr[1], 3), '\t', round(curr[2], 5), 
+                    ']\t', round(curr_lik, 3), '\t', 
+                    '\t[', round(prop[1], 3), '\t', round(prop[2], 5), ']\t',
+                    round(prop_lik, 3), '\t', round(r, 3), '\t', round(p, 3)))
+     
+     # Transition if the proposed state is better or if the coin flip succeeds.
+     if (p < r) { 
+       curr <- prop
+       curr_lik <- prop_lik
+       
+       # If the new likelihood is better than the best we've seen so far, replace 
+       # the best.
+       if (curr_lik > best_lik) {
+         best <- curr
+         best_lik <- curr_lik
+       }
+     }
+     
+     # Save the path, best state, and likelihoods so far.
+     write.table(path, file = '10/path.txt', row.names = F, col.names = F)
+     write.table(liks, file = '10/liks.txt', row.names = F, col.names = F)
+     write.table(best, file = '10/best.txt', row.names = F, col.names = F)
+   }
+   path[num_iter + 1, ] <- curr
+   liks[num_iter + 1] <- curr_lik
+   return(list(path, liks, best))
+ }
> 
> # Solve for optimal values via MCMC.
> target <- c(0.1, 0.25)
> start <- c(54.6267093106321, 0.087119522123414)
> results <- metropolis(start, target, num_sim = 1000, num_iter = 500)
1	[54.627	0.08712]	10.245		[54.826	0.0874]	8.678	0.209	0.556
2	[54.627	0.08712]	10.245		[54.5	0.08663]	10.924	1.972	0.416
3	[54.5	0.08663]	10.924		[54.752	0.08677]	10.328	0.551	0.192
4	[54.752	0.08677]	10.328		[54.924	0.0871]	10.426	1.103	0.793
5	[54.924	0.0871]	10.426		[54.966	0.08642]	9.049	0.252	0.172
6	[54.966	0.08642]	9.049		[55.058	0.08678]	8.724	0.722	0.356
7	[55.058	0.08678]	8.724		[55.184	0.0859]	9.543	2.269	0.969
8	[55.184	0.0859]	9.543		[55.013	0.08618]	10.336	2.211	0.924
9	[55.013	0.08618]	10.336		[54.896	0.08656]	10.638	1.352	0.264
10	[54.896	0.08656]	10.638		[54.728	0.08547]	8.296	0.096	0.177
11	[54.896	0.08656]	10.638		[54.767	0.08747]	9.116	0.218	0.996
12	[54.896	0.08656]	10.638		[54.966	0.0865]	9.109	0.217	0.347
13	[54.896	0.08656]	10.638		[55.034	0.08707]	10.591	0.954	0.712
14	[55.034	0.08707]	10.591		[54.891	0.08727]	10.25	0.711	0.86
15	[55.034	0.08707]	10.591		[54.999	0.08741]	9.439	0.316	0.008
16	[54.999	0.08741]	9.439		[54.944	0.08761]	9.19	0.779	0.806
17	[54.999	0.08741]	9.439		[54.908	0.08735]	9.214	0.798	0.274
18	[54.908	0.08735]	9.214		[54.92	0.08728]	9.343	1.138	0.992
19	[54.92	0.08728]	9.343		[55.023	0.0872]	10.555	3.359	0.582
20	[55.023	0.0872]	10.555		[54.973	0.08639]	10.903	1.417	0.066
21	[54.973	0.08639]	10.903		[55.118	0.08603]	9.676	0.293	0.835
22	[54.973	0.08639]	10.903		[54.97	0.08592]	10.154	0.473	0.822
23	[54.973	0.08639]	10.903		[54.847	0.0887]	7.557	0.035	0.971
24	[54.973	0.08639]	10.903		[55.045	0.08618]	10.016	0.412	0.332
25	[55.045	0.08618]	10.016		[55.02	0.08755]	8.655	0.256	0.228
26	[55.02	0.08755]	8.655		[55.113	0.08812]	9.651	2.706	0.487
27	[55.113	0.08812]	9.651		[55.136	0.08819]	7.75	0.149	0.96
28	[55.113	0.08812]	9.651		[55.116	0.08949]	7.264	0.092	0.323
29	[55.113	0.08812]	9.651		[55.152	0.08689]	10.037	1.471	0.221
30	[55.152	0.08689]	10.037		[55.117	0.08918]	8.178	0.156	0.05
31	[55.117	0.08918]	8.178		[55.022	0.09002]	7.671	0.602	0.517
32	[55.022	0.09002]	7.671		[55.027	0.08991]	7.523	0.863	0.407
33	[55.027	0.08991]	7.523		[55.057	0.08865]	8.089	1.761	0.7
34	[55.057	0.08865]	8.089		[54.963	0.08671]	9.252	3.2	0.671
35	[54.963	0.08671]	9.252		[55.038	0.08572]	11.922	14.434	0.012
36	[55.038	0.08572]	11.922		[55.059	0.08642]	7.93	0.018	0.2
37	[55.038	0.08572]	11.922		[55.066	0.08735]	8.816	0.045	0.494
38	[55.038	0.08572]	11.922		[55.136	0.08496]	11.195	0.484	0.103
39	[55.136	0.08496]	11.195		[55.226	0.08517]	10.55	0.524	0.645
40	[55.136	0.08496]	11.195		[55.168	0.08525]	9.465	0.177	0.872
41	[55.136	0.08496]	11.195		[55.093	0.08617]	9.881	0.269	0.87
42	[55.136	0.08496]	11.195		[55.136	0.08487]	13.253	7.826	0.559
43	[55.136	0.08487]	13.253		[55.09	0.08494]	10.677	0.076	0.108
44	[55.136	0.08487]	13.253		[55.203	0.08635]	9.556	0.025	0.7
45	[55.136	0.08487]	13.253		[55.061	0.08629]	10.698	0.078	0.566
46	[55.136	0.08487]	13.253		[55.161	0.08402]	11.045	0.11	0.11
47	[55.161	0.08402]	11.045		[55.435	0.08556]	10.294	0.472	0.528
48	[55.161	0.08402]	11.045		[54.94	0.08398]	14.024	19.667	0.229
49	[54.94	0.08398]	14.024		[54.855	0.08567]	9.521	0.011	0.128
50	[54.94	0.08398]	14.024		[55.119	0.08262]	9.864	0.016	0.724
51	[54.94	0.08398]	14.024		[54.869	0.08129]	8.268	0.003	0.981
52	[54.94	0.08398]	14.024		[55.011	0.0842]	11.222	0.061	0.376
53	[54.94	0.08398]	14.024		[55.104	0.0852]	10.88	0.043	0.346
54	[54.94	0.08398]	14.024		[55.159	0.08378]	9.548	0.011	0.348
55	[54.94	0.08398]	14.024		[54.986	0.08375]	10.314	0.024	0.401
56	[54.94	0.08398]	14.024		[55.056	0.08493]	14.425	1.494	0.35
57	[55.056	0.08493]	14.425		[54.924	0.086]	11.682	0.064	0.469
58	[55.056	0.08493]	14.425		[55.088	0.0854]	10.163	0.014	0.899
59	[55.056	0.08493]	14.425		[55.001	0.08481]	11.282	0.043	0.668
60	[55.056	0.08493]	14.425		[55.024	0.0852]	10.248	0.015	0.039
61	[55.056	0.08493]	14.425		[54.792	0.08663]	8.774	0.004	0.452
62	[55.056	0.08493]	14.425		[55.08	0.08479]	9.848	0.01	0.259
63	[55.056	0.08493]	14.425		[55.16	0.08487]	10.217	0.015	0.41
64	[55.056	0.08493]	14.425		[55.107	0.08584]	13.294	0.323	0.555
65	[55.056	0.08493]	14.425		[55.05	0.08226]	8.817	0.004	0.282
66	[55.056	0.08493]	14.425		[55.084	0.0866]	9.254	0.006	0.067
