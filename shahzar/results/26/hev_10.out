
R version 4.2.2 Patched (2022-11-10 r83330) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list = ls())
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 275507 14.8     663402 35.5   469283 25.1
Vcells 463357  3.6    8388608 64.0  1822500 14.0
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(foreach)
> library(doParallel)
Loading required package: iterators
Loading required package: parallel
> 
> # Set up the number of cores used for parallelization.
> num_cores <- 24
> registerDoParallel(num_cores)
> 
> #########################
> #### SEIR Simulation ####
> #########################
> time <- 365 # Number of days.
> inc <- 28 # Average incubation period length.
> inf <- 7 # Average infectious period length.
> N <- 1000 # Population size.
> 
> create_hh <- function() {
+   # Randomly sample household sizes such that total population is 1000 
+   # individuals.
+   hh_size <- sample(x = c(3, 4, 5, 6), size = 340, replace = T)
+   
+   # Keep households such that total population is < 1000.
+   hh_size <- hh_size[which(cumsum(hh_size) < N)]
+   
+   leftover <- N - sum(hh_size)
+   if (leftover < 3) {
+     hh <- 1:length(hh_size)
+     sampled <- sample(hh[hh_size < 6], leftover)
+     hh_size[sampled] <- hh_size[sampled] + 1
+   } else {
+     hh_size <- c(hh_size, leftover)
+   }
+   return(hh_size)
+ }
> 
> SEIR <- function(params, inc, inf, verbose = F) {
+   hh_size <- create_hh()
+   
+   # Create frame for running the simulation.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # S: susceptibility status.
+   # E: exposed status.
+   # E_count: number of days since exposed.
+   # I: infectious status.
+   # I_count: number of days since infectious.
+   # R: recovered status.
+   # INC: incubation period.
+   # INF: infectious period.
+   data <- data.frame(ID = 1:N,
+                     SIZE = rep(hh_size, times = hh_size),
+                     HH = rep(1:length(hh_size), times = hh_size), 
+                     S = c(0, rep(1, N - 1)), 
+                     E = c(1, rep(0, N - 1)),
+                     E_count = c(1, rep(0, N - 1)), 
+                     I = 0,
+                     I_count = 0, 
+                     R = 0, 
+                     INC = c(round(rnorm(1, inc, 2)), rep(0, N - 1)),
+                     INF = 0)
+   
+   # Create frame for storing results.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # TYPE: the kind of infection: household (H), community (C), or both (B).
+   # TIME: when the individual became infectious.
+   # S_num: number of susceptible people in individual's household when their 
+   #        infectious period begins.
+   # I_num: number of people in household that this individual infected over 
+   #        their infectious period.
+   results <- data[, 1:3] %>% mutate(TYPE = NA, TIME = NA, S_num = NA, I_num = 0)
+   results$TYPE[1] <- '0'
+   
+   for(t in 1:time) {
+     if (verbose) {
+       if (t %% 10 == 0) {
+         cat(paste0(t, ' '))
+       }
+     }
+     
+     # Anyone who has been infectious for as many days as their infectious period
+     # is now recovered.
+     recovered <- (data$INF > 0) & (data$I_count == data$INF)
+     if(sum(recovered, na.rm = T) > 0) {
+       data$R[recovered] <- 1
+       data$I[recovered] <- 0
+       data$I_count[recovered] <- 0 
+     }
+     
+     # Anyone who has been incubating for as many days as their incubation period
+     # is now infectious.
+     new_inf <- (data$INC > 0) & (data$E_count == data$INC)
+     num_new_inf <- sum(new_inf, na.rm = T)
+     if(num_new_inf > 0) {
+       # Change status to newly infectious and add infectious period.
+       data$I[new_inf] <- 1
+       random_inf <- rnorm(num_new_inf, mean = inf, sd = 1) %>% round()
+       data$INF[new_inf] <- random_inf
+       
+       # Remove exposure status and exposure count.
+       data$E[new_inf] <- 0
+       data$E_count[new_inf] <- 0 
+       
+       # Record time at which infectious period starts.
+       results$TIME[new_inf] <- t
+       
+       # Save the number of susceptible people in each infectious individual's 
+       # household.
+       S_data <- data %>% group_by(HH) %>% 
+         mutate(S_tot = sum(S)) %>% 
+         select(HH, S_tot)
+       results$S_num[new_inf == 1] <- S_data$S_tot[new_inf == 1]
+     }
+     
+     # I_H is the number of infections inside each household.
+     # I_C is the number of infections outside each household.
+     I_data <- data %>% group_by(HH) %>% 
+       mutate(I_H = sum(I)) %>% 
+       ungroup() %>% 
+       mutate(I_C = sum(I) - I_H)
+     
+     # Calculate household risk and community risk.
+     beta_H <- params[1]
+     beta_C <- params[2]
+     risk_H <- beta_H * data$S * I_data$I_H / N
+     risk_C <- beta_C * data$S * I_data$I_C / N
+     
+     # Each individual is infected from their household or community 
+     # independently with probabilities risk_H and risk_C.
+     new_inf_H <- rbinom(nrow(data), 1, risk_H)
+     new_inf_C <- rbinom(nrow(data), 1, risk_C)
+     
+     new_exposed <- (new_inf_H == 1) | (new_inf_C == 1)
+     num_new_exposed <- sum(new_exposed, na.rm = T)
+     if (num_new_exposed > 0) {
+       # Change status to newly exposed and add incubation period.
+       data$E[new_exposed] <- 1
+       random_inc <- rnorm(num_new_exposed, mean = inc, sd = 2) %>% round()
+       data$INC[new_exposed] <- random_inc
+       
+       # Remove susceptible status.
+       data$S[new_exposed] <- 0
+       
+       # Label community infections with C and household infections with H.
+       results$TYPE[new_inf_C == 1] <- 'C'
+       results$TYPE[new_inf_H == 1] <- 'H'
+       
+       # Get number of new infections in each household.
+       I_data <- I_data %>%
+         select(ID, HH, I, I_H) %>%
+         mutate(new_I_H = new_inf_H) %>%
+         group_by(HH) %>%
+         # Find households with at least 1 currently infectious individual. If 
+         # exactly 1 infectious individual in household, assign all new H 
+         # exposures to that individual. If there are multiple infectious 
+         # individuals, assign all infections to the infectious individual with 
+         # the first ID.
+         mutate(new_I_H = ifelse(I == 1 & ID == first(ID[I == 1]), 
+                                 sum(new_I_H), 0))
+       
+       results$I_num <- results$I_num + I_data$new_I_H
+         
+       # Label individuals with both a household and community infection with B.
+       results$TYPE[(new_inf_H == 1) & (new_inf_C == 1)] <- 'B'
+     }
+     
+     # Increment exposure and infectious counters.
+     data$E_count[data$E == 1] <- data$E_count[data$E == 1] + 1
+     data$I_count[data$I == 1] <- data$I_count[data$I == 1] + 1
+   }
+   return(results)
+ }
> 
> metrics <- function(results) {
+   # Incidence is the proportion of the population that became infected.
+   idc <- mean(!is.na(results$TIME))
+   
+   # If incidence is 0, the SAR is undefined.
+   sar <- NA
+   if (idc != 0) {
+     # The SAR is the average SAR for each individual that was infectious.
+     sar <- mean(results$I_num / results$S_num, na.rm = T)
+   }
+   return(c(idc, sar))
+ }
> 
> ##############################
> #### Metropolis Algorithm ####
> ##############################
> score <- function(obs, target) {
+   # The score is the L² distance of the observed values from the target.
+   return(sum((obs - target)^2))
+ }
> 
> # The likelihood is calculated by first averaging the incidence and SAR over n
> # simulations with the state parameters. The likelihood is the negative log
> # score of the average incidence and SAR.
> likelihood <- function(state, target, n = 300) {
+   # If either parameter is nonpositive, do not transition to that state.
+   if (any(state <= 0)) {
+     return(-Inf)
+   }
+   # Otherwise, find the average incidence and SAR and compute likelihood.
+   vals <- foreach (i = 1:n, .combine = c) %dopar% {
+     results <- SEIR(state, inc, inf)
+     metrics(results)
+   }
+   vals <- matrix(vals, n, byrow = T)
+   avg_vals <- colMeans(vals)
+   return(-log(score(avg_vals, target)))
+ }
> 
> # Proposal function
> q <- function(state, sds = c(0.1, 0.001)) {
+   # Sample from a multivariate normal distributions centered at the current 
+   # state. The SDs roughly correspond to the step-size of the chain for each 
+   # parameter.
+   return(rnorm(n = 2, mean = state, sd = sds))
+ }
> 
> # MCMC
> metropolis <- function(start, target, num_sim, num_iter) {
+   path <- matrix(NA, num_iter + 1, 2)
+   liks <- rep(NA, num_iter + 1)
+   
+   # Initialize current state.
+   curr <- start
+   curr_lik <- likelihood(curr, target, num_sim)
+   
+   # Initialize best state.
+   best <- curr
+   best_lik <- curr_lik
+   for (i in 1:num_iter) {
+     # Save the current state and its likelihood.
+     path[i, ] <- curr
+     liks[i] <- curr_lik
+     
+     # Get a proposed state and calculate its likelihood.
+     prop <- q(curr)
+     prop_lik <- likelihood(prop, target, num_sim)
+     
+     # Compute the ratio of the scores of the two states and generate a uniform 
+     # bit.
+     r <- exp(prop_lik - curr_lik)
+     p <- runif(1)
+     
+     # Print the current progress.
+     message(paste0(i, '\t[', round(curr[1], 3), '\t', round(curr[2], 5), 
+                    ']\t', round(curr_lik, 3), '\t', 
+                    '\t[', round(prop[1], 3), '\t', round(prop[2], 5), ']\t',
+                    round(prop_lik, 3), '\t', round(r, 3), '\t', round(p, 3)))
+     
+     # Transition if the proposed state is better or if the coin flip succeeds.
+     if (p < r) { 
+       curr <- prop
+       curr_lik <- prop_lik
+       
+       # If the new likelihood is better than the best we've seen so far, replace 
+       # the best.
+       if (curr_lik > best_lik) {
+         best <- curr
+         best_lik <- curr_lik
+       }
+     }
+     
+     # Save the path, best state, and likelihoods so far.
+     write.table(path, file = '10/path.txt', row.names = F, col.names = F)
+     write.table(liks, file = '10/liks.txt', row.names = F, col.names = F)
+     write.table(best, file = '10/best.txt', row.names = F, col.names = F)
+   }
+   path[num_iter + 1, ] <- curr
+   liks[num_iter + 1] <- curr_lik
+   return(list(path, liks, best))
+ }
> 
> # Solve for optimal values via MCMC.
> target <- c(0.1, 0.25)
> start <- c(55.0560239597619, 0.0849340061708643)
> results <- metropolis(start, target, num_sim = 1000, num_iter = 500)
1	[55.056	0.08493]	11.289		[55.083	0.08483]	13.976	14.696	0.366
2	[55.083	0.08483]	13.976		[55.101	0.08477]	9.931	0.018	0.626
3	[55.083	0.08483]	13.976		[55.208	0.08645]	10.694	0.038	0.763
4	[55.083	0.08483]	13.976		[55.295	0.08418]	10.133	0.021	0.532
5	[55.083	0.08483]	13.976		[54.964	0.08635]	10.978	0.05	0.313
6	[55.083	0.08483]	13.976		[55.171	0.08493]	9.597	0.013	0.489
7	[55.083	0.08483]	13.976		[55.176	0.08254]	10.049	0.02	0.336
8	[55.083	0.08483]	13.976		[55.117	0.08381]	9.94	0.018	0.541
9	[55.083	0.08483]	13.976		[55.209	0.08451]	9.856	0.016	0.494
10	[55.083	0.08483]	13.976		[54.926	0.08487]	8.281	0.003	0.898
11	[55.083	0.08483]	13.976		[54.969	0.08517]	11.236	0.065	0.041
12	[54.969	0.08517]	11.236		[54.899	0.08592]	11.188	0.953	0.034
13	[54.899	0.08592]	11.188		[54.969	0.08467]	11.214	1.026	0.813
14	[54.969	0.08467]	11.214		[54.902	0.08406]	8.45	0.063	0.15
15	[54.969	0.08467]	11.214		[54.975	0.08556]	10.671	0.581	0.491
16	[54.975	0.08556]	10.671		[55.005	0.08603]	12.588	6.796	0.434
17	[55.005	0.08603]	12.588		[55.032	0.08707]	10.059	0.08	0.59
18	[55.005	0.08603]	12.588		[55.018	0.08586]	9.626	0.052	0.995
19	[55.005	0.08603]	12.588		[54.924	0.08585]	10.574	0.134	0.119
20	[54.924	0.08585]	10.574		[54.93	0.08547]	10.87	1.343	0.081
21	[54.93	0.08547]	10.87		[54.926	0.0849]	11.893	2.784	0.787
22	[54.926	0.0849]	11.893		[54.975	0.0861]	12.917	2.783	0.966
23	[54.975	0.0861]	12.917		[55.08	0.08404]	9.902	0.049	0.795
24	[54.975	0.0861]	12.917		[54.84	0.08717]	11.301	0.199	0.234
25	[54.975	0.0861]	12.917		[55.005	0.08624]	9.57	0.035	0.776
26	[54.975	0.0861]	12.917		[55.072	0.08438]	9.869	0.047	0.489
27	[54.975	0.0861]	12.917		[55.047	0.08674]	9.027	0.02	0.861
28	[54.975	0.0861]	12.917		[54.985	0.08809]	8.691	0.015	0.568
29	[54.975	0.0861]	12.917		[54.975	0.0852]	10.456	0.085	0.537
30	[54.975	0.0861]	12.917		[54.904	0.08586]	13.447	1.699	0.57
31	[54.904	0.08586]	13.447		[54.859	0.0832]	8.664	0.008	0.403
32	[54.904	0.08586]	13.447		[54.992	0.08587]	8.7	0.009	0.394
33	[54.904	0.08586]	13.447		[55.026	0.0858]	9.044	0.012	0.41
34	[54.904	0.08586]	13.447		[54.878	0.08637]	7.977	0.004	0.844
35	[54.904	0.08586]	13.447		[55.038	0.0875]	8.593	0.008	0.721
36	[54.904	0.08586]	13.447		[54.91	0.08491]	11.578	0.154	0.247
37	[54.904	0.08586]	13.447		[54.98	0.0859]	9.184	0.014	0.035
38	[54.904	0.08586]	13.447		[54.914	0.08669]	10.625	0.059	0.832
39	[54.904	0.08586]	13.447		[54.784	0.0865]	8.957	0.011	0.606
40	[54.904	0.08586]	13.447		[54.819	0.08632]	10.28	0.042	0.163
41	[54.904	0.08586]	13.447		[54.841	0.0843]	11.883	0.209	0.718
42	[54.904	0.08586]	13.447		[55.104	0.08539]	9.993	0.032	0.401
43	[54.904	0.08586]	13.447		[54.831	0.08497]	12.41	0.355	0.228
44	[54.831	0.08497]	12.41		[54.905	0.08667]	9.321	0.046	0.336
45	[54.831	0.08497]	12.41		[54.864	0.08441]	11.878	0.588	0.041
46	[54.864	0.08441]	11.878		[54.768	0.08555]	10.898	0.375	0.861
47	[54.864	0.08441]	11.878		[54.97	0.08487]	9.062	0.06	0.521
48	[54.864	0.08441]	11.878		[54.919	0.08424]	10.626	0.286	0.679
49	[54.864	0.08441]	11.878		[54.919	0.08563]	9.58	0.1	0.467
50	[54.864	0.08441]	11.878		[54.936	0.08442]	8.966	0.054	0.786
51	[54.864	0.08441]	11.878		[55.039	0.08384]	12.52	1.899	0.95
52	[55.039	0.08384]	12.52		[55.139	0.08403]	9.29	0.04	0.864
