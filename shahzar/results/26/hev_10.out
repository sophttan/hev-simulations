
R version 4.2.2 Patched (2022-11-10 r83330) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list = ls())
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 275507 14.8     663402 35.5   469283 25.1
Vcells 463357  3.6    8388608 64.0  1822500 14.0
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(foreach)
> library(doParallel)
Loading required package: iterators
Loading required package: parallel
> 
> # Set up the number of cores used for parallelization.
> num_cores <- 24
> registerDoParallel(num_cores)
> 
> #########################
> #### SEIR Simulation ####
> #########################
> time <- 365 # Number of days.
> inc <- 28 # Average incubation period length.
> inf <- 7 # Average infectious period length.
> N <- 1000 # Population size.
> 
> create_hh <- function() {
+   # Randomly sample household sizes such that total population is 1000 
+   # individuals.
+   hh_size <- sample(x = c(3, 4, 5, 6), size = 340, replace = T)
+   
+   # Keep households such that total population is < 1000.
+   hh_size <- hh_size[which(cumsum(hh_size) < N)]
+   
+   leftover <- N - sum(hh_size)
+   if (leftover < 3) {
+     hh <- 1:length(hh_size)
+     sampled <- sample(hh[hh_size < 6], leftover)
+     hh_size[sampled] <- hh_size[sampled] + 1
+   } else {
+     hh_size <- c(hh_size, leftover)
+   }
+   return(hh_size)
+ }
> 
> SEIR <- function(params, inc, inf, verbose = F) {
+   hh_size <- create_hh()
+   
+   # Create frame for running the simulation.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # S: susceptibility status.
+   # E: exposed status.
+   # E_count: number of days since exposed.
+   # I: infectious status.
+   # I_count: number of days since infectious.
+   # R: recovered status.
+   # INC: incubation period.
+   # INF: infectious period.
+   data <- data.frame(ID = 1:N,
+                     SIZE = rep(hh_size, times = hh_size),
+                     HH = rep(1:length(hh_size), times = hh_size), 
+                     S = c(0, rep(1, N - 1)), 
+                     E = c(1, rep(0, N - 1)),
+                     E_count = c(1, rep(0, N - 1)), 
+                     I = 0,
+                     I_count = 0, 
+                     R = 0, 
+                     INC = c(round(rnorm(1, inc, 2)), rep(0, N - 1)),
+                     INF = 0)
+   
+   # Create frame for storing results.
+   # ID: ID of individual.
+   # SIZE: size of individual's household.
+   # HH: ID of individual's household.
+   # TYPE: the kind of infection: household (H), community (C), or both (B).
+   # TIME: when the individual became infectious.
+   # S_num: number of susceptible people in individual's household when their 
+   #        infectious period begins.
+   # I_num: number of people in household that this individual infected over 
+   #        their infectious period.
+   results <- data[, 1:3] %>% mutate(TYPE = NA, TIME = NA, S_num = NA, I_num = 0)
+   results$TYPE[1] <- '0'
+   
+   for(t in 1:time) {
+     if (verbose) {
+       if (t %% 10 == 0) {
+         cat(paste0(t, ' '))
+       }
+     }
+     
+     # Anyone who has been infectious for as many days as their infectious period
+     # is now recovered.
+     recovered <- (data$INF > 0) & (data$I_count == data$INF)
+     if(sum(recovered, na.rm = T) > 0) {
+       data$R[recovered] <- 1
+       data$I[recovered] <- 0
+       data$I_count[recovered] <- 0 
+     }
+     
+     # Anyone who has been incubating for as many days as their incubation period
+     # is now infectious.
+     new_inf <- (data$INC > 0) & (data$E_count == data$INC)
+     num_new_inf <- sum(new_inf, na.rm = T)
+     if(num_new_inf > 0) {
+       # Change status to newly infectious and add infectious period.
+       data$I[new_inf] <- 1
+       random_inf <- rnorm(num_new_inf, mean = inf, sd = 1) %>% round()
+       data$INF[new_inf] <- random_inf
+       
+       # Remove exposure status and exposure count.
+       data$E[new_inf] <- 0
+       data$E_count[new_inf] <- 0 
+       
+       # Record time at which infectious period starts.
+       results$TIME[new_inf] <- t
+       
+       # Save the number of susceptible people in each infectious individual's 
+       # household.
+       S_data <- data %>% group_by(HH) %>% 
+         mutate(S_tot = sum(S)) %>% 
+         select(HH, S_tot)
+       results$S_num[new_inf == 1] <- S_data$S_tot[new_inf == 1]
+     }
+     
+     # I_H is the number of infections inside each household.
+     # I_C is the number of infections outside each household.
+     I_data <- data %>% group_by(HH) %>% 
+       mutate(I_H = sum(I)) %>% 
+       ungroup() %>% 
+       mutate(I_C = sum(I) - I_H)
+     
+     # Calculate household risk and community risk.
+     beta_H <- params[1]
+     beta_C <- params[2]
+     risk_H <- beta_H * data$S * I_data$I_H / N
+     risk_C <- beta_C * data$S * I_data$I_C / N
+     
+     # Each individual is infected from their household or community 
+     # independently with probabilities risk_H and risk_C.
+     new_inf_H <- rbinom(nrow(data), 1, risk_H)
+     new_inf_C <- rbinom(nrow(data), 1, risk_C)
+     
+     new_exposed <- (new_inf_H == 1) | (new_inf_C == 1)
+     num_new_exposed <- sum(new_exposed, na.rm = T)
+     if (num_new_exposed > 0) {
+       # Change status to newly exposed and add incubation period.
+       data$E[new_exposed] <- 1
+       random_inc <- rnorm(num_new_exposed, mean = inc, sd = 2) %>% round()
+       data$INC[new_exposed] <- random_inc
+       
+       # Remove susceptible status.
+       data$S[new_exposed] <- 0
+       
+       # Label community infections with C and household infections with H.
+       results$TYPE[new_inf_C == 1] <- 'C'
+       results$TYPE[new_inf_H == 1] <- 'H'
+       
+       # Get number of new infections in each household.
+       I_data <- I_data %>%
+         select(ID, HH, I, I_H) %>%
+         mutate(new_I_H = new_inf_H) %>%
+         group_by(HH) %>%
+         # Find households with at least 1 currently infectious individual. If 
+         # exactly 1 infectious individual in household, assign all new H 
+         # exposures to that individual. If there are multiple infectious 
+         # individuals, assign all infections to the infectious individual with 
+         # the first ID.
+         mutate(new_I_H = ifelse(I == 1 & ID == first(ID[I == 1]), 
+                                 sum(new_I_H), 0))
+       
+       results$I_num <- results$I_num + I_data$new_I_H
+         
+       # Label individuals with both a household and community infection with B.
+       results$TYPE[(new_inf_H == 1) & (new_inf_C == 1)] <- 'B'
+     }
+     
+     # Increment exposure and infectious counters.
+     data$E_count[data$E == 1] <- data$E_count[data$E == 1] + 1
+     data$I_count[data$I == 1] <- data$I_count[data$I == 1] + 1
+   }
+   return(results)
+ }
> 
> metrics <- function(results) {
+   # Incidence is the proportion of the population that became infected.
+   idc <- mean(!is.na(results$TIME))
+   
+   # If incidence is 0, the SAR is undefined.
+   sar <- NA
+   if (idc != 0) {
+     # The SAR is the average SAR for each individual that was infectious.
+     sar <- mean(results$I_num / results$S_num, na.rm = T)
+   }
+   return(c(idc, sar))
+ }
> 
> ##############################
> #### Metropolis Algorithm ####
> ##############################
> score <- function(obs, target) {
+   # The score is the L² distance of the observed values from the target.
+   return(sum((obs - target)^2))
+ }
> 
> # The likelihood is calculated by first averaging the incidence and SAR over n
> # simulations with the state parameters. The likelihood is the negative log
> # score of the average incidence and SAR.
> likelihood <- function(state, target, n = 300) {
+   # If either parameter is nonpositive, do not transition to that state.
+   if (any(state <= 0)) {
+     return(-Inf)
+   }
+   # Otherwise, find the average incidence and SAR and compute likelihood.
+   vals <- foreach (i = 1:n, .combine = c) %dopar% {
+     results <- SEIR(state, inc, inf)
+     metrics(results)
+   }
+   vals <- matrix(vals, n, byrow = T)
+   avg_vals <- colMeans(vals)
+   return(-log(score(avg_vals, target)))
+ }
> 
> # Proposal function
> q <- function(state, sds = c(0.05, 0.0005)) {
+   # Sample from a multivariate normal distributions centered at the current 
+   # state. The SDs roughly correspond to the step-size of the chain for each 
+   # parameter.
+   return(rnorm(n = 2, mean = state, sd = sds))
+ }
> 
> # MCMC
> metropolis <- function(start, target, num_sim, num_iter) {
+   path <- matrix(NA, num_iter + 1, 2)
+   liks <- rep(NA, num_iter + 1)
+   
+   # Initialize current state.
+   curr <- start
+   curr_lik <- likelihood(curr, target, num_sim)
+   
+   # Initialize best state.
+   best <- curr
+   best_lik <- curr_lik
+   for (i in 1:num_iter) {
+     # Save the current state and its likelihood.
+     path[i, ] <- curr
+     liks[i] <- curr_lik
+     
+     # Get a proposed state and calculate its likelihood.
+     prop <- q(curr)
+     prop_lik <- likelihood(prop, target, num_sim)
+     
+     # Compute the ratio of the scores of the two states and generate a uniform 
+     # bit.
+     r <- exp(prop_lik - curr_lik)
+     p <- runif(1)
+     
+     # Print the current progress.
+     message(paste0(i, '\t[', round(curr[1], 3), '\t', round(curr[2], 5), 
+                    ']\t', round(curr_lik, 3), '\t', 
+                    '\t[', round(prop[1], 3), '\t', round(prop[2], 5), ']\t',
+                    round(prop_lik, 3), '\t', round(r, 3), '\t', round(p, 3)))
+     
+     # Transition if the proposed state is better or if the coin flip succeeds.
+     if (p < r) { 
+       curr <- prop
+       curr_lik <- prop_lik
+       
+       # If the new likelihood is better than the best we've seen so far, replace 
+       # the best.
+       if (curr_lik > best_lik) {
+         best <- curr
+         best_lik <- curr_lik
+       }
+     }
+     
+     # Save the path, best state, and likelihoods so far.
+     write.table(path, file = '10/path.txt', row.names = F, col.names = F)
+     write.table(liks, file = '10/liks.txt', row.names = F, col.names = F)
+     write.table(best, file = '10/best.txt', row.names = F, col.names = F)
+   }
+   path[num_iter + 1, ] <- curr
+   liks[num_iter + 1] <- curr_lik
+   return(list(path, liks, best))
+ }
> 
> # Solve for optimal values via MCMC.
> target <- c(0.1, 0.25)
> start <- c(54.8059305155253, 0.0857069414737171)
> results <- metropolis(start, target, num_sim = 1000, num_iter = 500)
1	[54.806	0.08571]	9.921		[54.919	0.08577]	11.088	3.211	0.706
2	[54.919	0.08577]	11.088		[54.924	0.08533]	10.493	0.552	0.644
3	[54.919	0.08577]	11.088		[54.921	0.08577]	8.874	0.109	0.045
4	[54.921	0.08577]	8.874		[54.945	0.08462]	12.144	26.317	0.354
5	[54.945	0.08462]	12.144		[54.98	0.08478]	8.995	0.043	0.685
6	[54.945	0.08462]	12.144		[54.86	0.08413]	8.781	0.035	0.579
7	[54.945	0.08462]	12.144		[54.913	0.08464]	8.555	0.028	0.523
8	[54.945	0.08462]	12.144		[54.956	0.08399]	9.823	0.098	0.123
9	[54.945	0.08462]	12.144		[54.983	0.08344]	9.791	0.095	0.553
10	[54.945	0.08462]	12.144		[54.897	0.08372]	8.907	0.039	0.698
11	[54.945	0.08462]	12.144		[54.897	0.08465]	9.41	0.065	0.713
12	[54.945	0.08462]	12.144		[54.876	0.08502]	10.398	0.174	0.644
13	[54.945	0.08462]	12.144		[54.874	0.08429]	11.629	0.598	0.828
14	[54.945	0.08462]	12.144		[54.867	0.08492]	10.736	0.245	0.437
15	[54.945	0.08462]	12.144		[55.032	0.08456]	11.415	0.482	0.121
16	[55.032	0.08456]	11.415		[55.015	0.08519]	10.874	0.582	0.211
17	[55.015	0.08519]	10.874		[55.123	0.08517]	10.58	0.745	0.222
18	[55.123	0.08517]	10.58		[55.166	0.08565]	9.784	0.451	0.004
19	[55.166	0.08565]	9.784		[55.298	0.08482]	8.664	0.326	0.487
20	[55.166	0.08565]	9.784		[55.153	0.0857]	12.04	9.542	0.538
21	[55.153	0.0857]	12.04		[55.132	0.08598]	10.915	0.325	0.234
22	[55.132	0.08598]	10.915		[55.17	0.08662]	10.435	0.619	0.871
23	[55.132	0.08598]	10.915		[55.184	0.08573]	11.603	1.99	0.574
24	[55.184	0.08573]	11.603		[55.268	0.08526]	11.108	0.61	0.549
25	[55.268	0.08526]	11.108		[55.258	0.08587]	10.364	0.475	0.85
26	[55.268	0.08526]	11.108		[55.233	0.08555]	10.369	0.478	0.491
27	[55.268	0.08526]	11.108		[55.253	0.0857]	9.493	0.199	0.428
28	[55.268	0.08526]	11.108		[55.219	0.08559]	9.935	0.309	0.433
29	[55.268	0.08526]	11.108		[55.334	0.0854]	12.813	5.505	0.426
30	[55.334	0.0854]	12.813		[55.332	0.08506]	11.348	0.231	0.841
31	[55.334	0.0854]	12.813		[55.391	0.08516]	11.209	0.201	0.443
32	[55.334	0.0854]	12.813		[55.304	0.08642]	10.725	0.124	0.048
33	[55.304	0.08642]	10.725		[55.295	0.08659]	9.712	0.363	0.769
34	[55.304	0.08642]	10.725		[55.353	0.0868]	8.315	0.09	0.676
35	[55.304	0.08642]	10.725		[55.334	0.08611]	9.184	0.214	0.655
36	[55.304	0.08642]	10.725		[55.225	0.08624]	10.488	0.79	0.232
37	[55.225	0.08624]	10.488		[55.244	0.08584]	9.16	0.265	0.866
38	[55.225	0.08624]	10.488		[55.205	0.08675]	8.961	0.217	0.268
39	[55.225	0.08624]	10.488		[55.232	0.08679]	9.296	0.303	0.151
40	[55.232	0.08679]	9.296		[55.202	0.08718]	11.671	10.757	0.386
41	[55.202	0.08718]	11.671		[55.148	0.0867]	9.882	0.167	0.973
42	[55.202	0.08718]	11.671		[55.223	0.08779]	8.961	0.067	0.605
