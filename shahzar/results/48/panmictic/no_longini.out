
R version 4.3.0 (2023-04-21) -- "Already Tomorrow"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list = ls())
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 284765 15.3     664565 35.5   464468 24.9
Vcells 490458  3.8    8388608 64.0  1837328 14.1
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(readr)
> library(foreach)
> library(doParallel)
Loading required package: iterators
Loading required package: parallel
> 
> # Set up the number of cores used for parallelization.
> message(detectCores())
24
> num_cores <- detectCores()
> registerDoParallel(num_cores)
> 
> prp_true <- function(results) {
+   cases <- results[!is.na(results$TIME), ]
+   cases_HH = (cases$TYPE == 'H') | (cases$TYPE == 'HC') | (cases$TYPE == 'HCE')
+   prp <- mean(cases_HH)
+   return(prp)
+ }
> 
> method_HH <- function(results) {
+   f <- results %>% filter(!is.na(TIME))
+   f <- f %>% group_by(HH) %>% 
+     mutate(day_limits = list(TIME)) %>%
+     ungroup() %>%
+     rowwise() %>%
+     mutate(IS_H = any((TIME - unlist(day_limits)) < 45 & (TIME - unlist(day_limits)) > 7))
+   
+   return(mean(f$IS_H))
+ }
> 
> probability <- function(cases, index, rel_p_hh=1) {
+   inc_prim <- cases$TIME
+   inc_sec <- cases$TIME[index]
+   hh_prim <- cases$HH
+   hh_sec <- cases$HH[index]
+   # calculate relative likelihood that primary case caused secondary case based on their incidences
+   # serial interval is approximate
+   results <- (rel_p_hh*(hh_prim==hh_sec)+(hh_prim!=hh_sec))*dnorm(inc_sec-inc_prim, mean=31.5, sd=4)
+   # if primary case happens after secondary case, set probability to 0
+   results[inc_prim >= inc_sec] <- 0
+   if(sum(results) == 0){
+     return(results)
+   }
+   
+   return(results/sum(results))
+ }
> 
> method_R <- function(results) {
+   cases <- results %>% 
+     filter(!is.na(TIME)) %>%
+     mutate(ID = 1:n())
+   
+   R <- rep(0, nrow(cases))
+   R_HH <- rep(0, nrow(cases))
+   
+   for (k in 1:nrow(cases)) {
+     probs <- probability(cases, k, 1)
+     HH_probs <- probs
+     HH_probs[cases$HH != cases$HH[k]] <- 0
+     R <- R + probs
+     R_HH <- R_HH + HH_probs
+   }
+   return(mean(R_HH) / mean(R))
+ }
> 
> values <- function(results) {
+   return(method_R(results))
+ }
> 
> # 5% Cumulative Incidence
> n_sims <- 999
> vals <- foreach (i = 0:n_sims, .combine = 'c') %dopar% {
+   results <- read.csv(paste0('5/', i, '.csv'))
+   values(results)
+ }
> vals <- matrix(vals, n_sims + 1, byrow = T)
> saveRDS(vals, file = '5/no_longini.rds')
> write.table(vals, file = '5/no_longini.txt', row.names = F, col.names = F)
> 
> 
> # 10% Cumulative Incidence
> n_sims <- 999
> vals <- foreach (i = 0:n_sims, .combine = 'c') %dopar% {
+   results <- read.csv(paste0('10/', i, '.csv'))
+   values(results)
+ }
> vals <- matrix(vals, n_sims + 1, byrow = T)
> saveRDS(vals, file = '10/no_longini.rds')
> write.table(vals, file = '10/no_longini.txt', row.names = F, col.names = F)
> 
> 
> # 30% Cumulative Incidence
> n_sims <- 999
> vals <- foreach (i = 0:n_sims, .combine = 'c') %dopar% {
+   results <- read.csv(paste0('30/', i, '.csv'))
+   values(results)
+ }
> vals <- matrix(vals, n_sims + 1, byrow = T)
> saveRDS(vals, file = '30/no_longini.rds')
> write.table(vals, file = '30/no_longini.txt', row.names = F, col.names = F)
> 
> 
> 
> proc.time()
   user  system elapsed 
 83.358   9.757   7.823 
