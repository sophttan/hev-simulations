{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "38e6257a-2529-47b5-afe0-85dcca43d179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager\n",
    "rc('font', family='serif')\n",
    "rc('text', usetex=True)\n",
    "rc('font', size=12)        #22\n",
    "rc('xtick', labelsize=12)  #15\n",
    "rc('ytick', labelsize=12)  #15\n",
    "rc('legend', fontsize=12)  #15\n",
    "rc('text.latex', preamble=r'\\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fddcd8-df63-4ae8-aba9-3a92620cdb38",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0830ad85-8df0-4efd-98b3-87af81bda3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = 365\n",
    "inc = 28\n",
    "inf = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9212eafb-acd4-456f-8b28-f4c888ef4938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_hh():\n",
    "    hh_size = np.random.choice([3, 4, 5, 6], size = 340, replace = True)\n",
    "    hh_size = hh_size[np.cumsum(hh_size) < 1000]\n",
    "    \n",
    "    leftover = 1000 - hh_size.sum()\n",
    "    if leftover < 3:\n",
    "        # Randomly sample leftover amount indices from hh_size, and add one\n",
    "        hh = np.arange(len(hh_size))\n",
    "        idx = np.random.choice(hh[hh_size < 6], size = leftover, replace = False)\n",
    "        hh_size[idx] += 1\n",
    "    else:\n",
    "        hh_size = np.append(hh_size, leftover)\n",
    "    return hh_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57d232f1-3dbc-49c4-8dac-e33c1eb1d3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SEIR(beta_H, beta_C, inc, inf, verbose = 0):\n",
    "    hh_size = create_hh()\n",
    "    \n",
    "    # ID: ID of individual\n",
    "    # SIZE: size of individual's household\n",
    "    # HH: ID of individual's household\n",
    "    # S: susceptibility status\n",
    "    # E: exposed status\n",
    "    # E_count: number of days since exposed\n",
    "    # I: infectious status\n",
    "    # I_count: number of days since infectious\n",
    "    # R: recovered status\n",
    "    # INC: incubation period\n",
    "    # INF: infectious period\n",
    "    data = pd.DataFrame({'ID': range(1000),\n",
    "                         'SIZE': np.repeat(hh_size, repeats = hh_size),\n",
    "                         'HH': np.repeat(range(len(hh_size)), repeats = hh_size),\n",
    "                         'S': np.append(0, np.ones(999)),\n",
    "                         'E': np.append(1, np.zeros(999)),\n",
    "                         'E_count': np.append(1, np.zeros(999)),\n",
    "                         'I': np.zeros(1000),\n",
    "                         'I_count': np.zeros(1000),\n",
    "                         'R': np.zeros(1000),\n",
    "                         'INC': np.append(np.round(stats.norm.rvs(inc, 2)), np.zeros(999)),\n",
    "                         'INF': np.zeros(1000),\n",
    "                        })\n",
    "    \n",
    "    # Create frame for storing results\n",
    "    results = data.loc[:, 'ID':'HH']\n",
    "    results['TYPE'] = np.nan\n",
    "    results.loc[0, 'TYPE'] = '0'\n",
    "    results['TIME'] = np.nan\n",
    "    results.loc[0, 'TIME'] = 0\n",
    "    \n",
    "    for t in range(time):\n",
    "        if verbose:\n",
    "            if t % 10 == 0: print(t, end = ' ')\n",
    "        \n",
    "        # Anyone who has been infectious for as many days as their infectious\n",
    "        # period is now recovered.\n",
    "        recovered = (data['INF'] > 0) & (data['I_count'] == data['INF'])\n",
    "        if sum(recovered) > 0:\n",
    "            data.loc[recovered, 'R'] = 1\n",
    "            data.loc[recovered, 'I'] = 0\n",
    "            data.loc[recovered, 'I_count'] = 0\n",
    "\n",
    "        # Anyone who has been incubating for as many days as their incubation\n",
    "        # period is now infectious.\n",
    "        new_inf = (data['INC'] > 0) & (data['E_count'] == data['INC'])\n",
    "        num_new_inf = sum(new_inf)\n",
    "        if num_new_inf > 0:\n",
    "            random_inf = np.round(stats.norm.rvs(inf, 1, size = num_new_inf))\n",
    "            data.loc[new_inf, 'I'] = 1\n",
    "            data.loc[new_inf, 'INF'] = random_inf\n",
    "            data.loc[new_inf, 'E'] = 0\n",
    "            data.loc[new_inf, 'E_count'] = 0\n",
    "\n",
    "        # I_H is the number of infections in each household.\n",
    "        # I_C is the number of infections outside a given household.\n",
    "        I_H = data.groupby('HH').sum()['I']\n",
    "        summary = pd.DataFrame({'I_H': I_H, \n",
    "                                'I_C': data.sum()['I'] - I_H\n",
    "                               })\n",
    "        # dd is a frame where each individual is assigned their household's\n",
    "        # I_H and I_C numbers.\n",
    "        dd = data[['HH', 'S']].copy()\n",
    "        dd['I_H'] = dd.apply(lambda x: summary.loc[x['HH'], 'I_H'], axis = 1)\n",
    "        dd['I_C'] = dd.apply(lambda x: summary.loc[x['HH'], 'I_C'], axis = 1)\n",
    "\n",
    "        # Calculate household risk and community risk\n",
    "        risk_H = dd['S'] * beta_H * dd['I_H'] / 1000\n",
    "        risk_C = dd['S'] * beta_C * dd['I_C'] / 1000\n",
    "\n",
    "        # Calculate new household and community infections\n",
    "        new_inf_H = stats.binom.rvs(1, risk_H, size = data.shape[0])\n",
    "        new_inf_C = stats.binom.rvs(1, risk_C, size = data.shape[0])\n",
    "        new_exposed = (new_inf_H == 1) | (new_inf_C == 1)\n",
    "\n",
    "        num_new_exposed = sum(new_exposed)\n",
    "        if num_new_exposed > 0:\n",
    "            data.loc[new_exposed, 'E'] = 1\n",
    "            random_inc = np.round(stats.norm.rvs(inc, 2, size = num_new_exposed))\n",
    "            data.loc[new_exposed, 'E'] = 1\n",
    "            data.loc[new_exposed, 'INC'] = random_inc\n",
    "\n",
    "            results['TYPE'].where(~((new_inf_H == 1) & (new_inf_C == 1)) | ~pd.isna(results['TYPE']), 'B', inplace = True)\n",
    "            results['TYPE'].where(~(new_inf_H == 1) | ~pd.isna(results['TYPE']), 'H', inplace = True)\n",
    "            results['TYPE'].where(~(new_inf_C == 1) | ~pd.isna(results['TYPE']), 'C', inplace = True)\n",
    "            results['TIME'].where(~(new_exposed == 1) | ~pd.isna(results['TIME']), t, inplace = True)\n",
    "        \n",
    "        data.loc[data['E'] == 1, 'E_count'] += 1\n",
    "        data.loc[data['I'] == 1, 'I_count'] += 1\n",
    "        data.loc[data['E'] == 1, 'S'] = 0\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3bc77d82-8bd1-4b6b-82ed-2fa71290b658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics(results):\n",
    "    state = results[~pd.isna(results['TIME'])]\n",
    "    i = state.shape[0]/1000\n",
    "    \n",
    "    #p_hh = np.nan\n",
    "    #if i != 0:\n",
    "    #    p_hh = state[state['TYPE'] == 'H'].shape[0] / state.shape[0]\n",
    "    #return i, p_hh\n",
    "    \n",
    "    sar = np.nan\n",
    "    if i != 0:\n",
    "        num_primary = np.sum(results.groupby('HH')['TIME'].sum() > 0) # households that were infected\n",
    "        idx = results.groupby('HH')['TYPE'].apply(lambda x: ~np.all(x.isna()))\n",
    "        num_contact = (results.groupby('HH')['SIZE'].sum()[idx]**(1/2)).sum() # total people in all those households\n",
    "        sar = state[(state['TYPE'] == 'H') | (state['TYPE'] == 'B')].shape[0] / (num_contact - num_primary)\n",
    "    \n",
    "    return i, sar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "23b6b138-1efb-42b7-a801-cc197b58afcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score(results, target):\n",
    "    return np.sum((np.array(metrics(results)) - target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ce3c4d09-7ac6-4c02-8432-30a80b1f16c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3 , 0.25])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "add14bb2-2827-418b-93d6-42ecc4cf4466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.097, 0.21505376344086022)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fc5b503f-54f3-469e-930f-9f5f43f23d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3 , 0.25])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b36a2102-fd0e-4f8c-a92c-1211cb0dbbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042430239449647356"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(results, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7fc1538a-81b7-434a-a962-e5a01f290fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.159893976379459"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(score(results, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781bf5a5-9fdb-4dc3-a8d1-7a2b1723a7c4",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9f15cc84-bc1c-4ecf-9596-04abc5f4b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create likelihood, prior, and posterior\n",
    "def likelihood(state):\n",
    "    beta_H, beta_C = state\n",
    "    results = SEIR(beta_H, beta_C, inc, inf)\n",
    "    lik = -np.log(score(results, target))\n",
    "    \n",
    "    # Poisson likelihood\n",
    "    #lik = stats.poisson.logpmf(I_obs, I_fit).sum()\n",
    "    \n",
    "    # L1 score likelihood\n",
    "    #lik = -np.log(np.mean(abs(I_fit - I_obs)))\n",
    "    \n",
    "    # L2 score likelihood\n",
    "    #lik = -np.log(np.mean((I_fit - I_obs)**2))\n",
    "    \n",
    "    return lik\n",
    "\n",
    "def prior(state):\n",
    "    beta_H, beta_C = state\n",
    "    return stats.gamma.logpdf(beta_H, 10, 0.5) + stats.norm.logpdf(beta_C, 4, 8)\n",
    "\n",
    "def posterior(state):\n",
    "    return likelihood(state) + prior(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ac3e3027-8c2d-4fe0-967b-7455a888e4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metropolis algorithm\n",
    "\n",
    "# Proposal function\n",
    "def q(state):\n",
    "    beta_H, beta_C = state\n",
    "    r = [beta_H**2, beta_C**2 / 0.01]\n",
    "    v = np.array([beta_H, beta_C / 0.01])\n",
    "    return stats.gamma.rvs(r, scale = 1 / v, size = 2)\n",
    "\n",
    "# MCMC\n",
    "def metropolis(start, num_iter):\n",
    "    best = np.zeros(2)\n",
    "    best_lik = -np.inf\n",
    "    \n",
    "    chain = np.zeros((num_iter + 1, 2))\n",
    "    chain[0] = start\n",
    "    for i in range(num_iter):\n",
    "        print(i, np.round(chain[i], 3), end = '\\t')\n",
    "        lik = likelihood(chain[i])\n",
    "        print(np.round(lik, 3), end = '\\t')\n",
    "        if lik > best_lik:\n",
    "            best = chain[i]\n",
    "            best_lik = lik\n",
    "        proposal = q(chain[i])\n",
    "        print(np.round(proposal, 3))\n",
    "        pos = lik + prior(chain[i])\n",
    "        p = np.exp(posterior(proposal) - pos)\n",
    "        #p = np.exp(posterior(proposal) - posterior(chain[i]))\n",
    "        if stats.uniform.rvs() < p:\n",
    "            chain[i + 1] = proposal\n",
    "        else:\n",
    "            chain[i + 1] = chain[i]\n",
    "    return chain, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bc8b2d1c-917b-4f40-a54f-6761feb80c73",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.    0.12]\t3.776\t[29.429  0.112]\n",
      "[29.429  0.112]\t2.403\t[3.1077e+01 2.1000e-02]\n",
      "[29.429  0.112]\t2.396\t[29.08   0.116]\n",
      "[29.08   0.116]\t2.201\t[29.254  0.136]\n",
      "[29.254  0.136]\t1.896\t[29.239  0.253]\n",
      "[29.239  0.253]\t1.116\t[30.082  0.084]\n",
      "[30.082  0.084]\t1.885\t[30.556  0.036]\n",
      "[30.556  0.036]\t1.56\t[31.052  0.162]\n",
      "[31.052  0.162]\t2.077\t[32.187  0.119]\n",
      "[32.187  0.119]\t5.145\t[31.775  0.066]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([32.18724048,  0.11924955])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve for optimal values via MCMC\n",
    "target = np.array([0.3, 0.25])\n",
    "\n",
    "chain, best = metropolis([30, 0.12], 10)\n",
    "mcmc_opt = best\n",
    "\n",
    "mcmc_opt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
